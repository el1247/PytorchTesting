{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Text Classification with the torchtext library, Reloaded\n",
    "Notebook for following along with Pytorch Text NLP tutorials that is looking to use the torchtext library to build the dataset for text classification analysis [Pytorch](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)  website tutorial. This notebook's purpose is to reload the model created in the main version of this notebook. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09d0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"textClassifier_AG_NEWS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d660636a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu. Cuda available: False\n",
      "Torch current seed = 978401694287300\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(1247) #setting seed value\n",
    "print(f\"Device: {device}. Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch current seed = {torch.seed()}\")\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2827ad3",
   "metadata": {},
   "source": [
    "### Data Loading and Manipulation Functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>collate_batch - uses pipelines to process input batch of data</li>\n",
    "    <li>yield_tokens - processes data_iter for build_vocab_from_iterator()</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a02c65e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and manipulation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Data loading and manipulation function definition cell\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "        \n",
    "        \n",
    "label_pipeline = lambda x: int(x) - 1        \n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "print(\"Data loading and manipulation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af710121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created and dataloaders defined.\n"
     ]
    }
   ],
   "source": [
    "#Build a vocab with the raw training dataset, generating data batch and iter\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "     \n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset)*0.95)\n",
    "\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset)-num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "print(\"Vocab created and dataloaders defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>TextClassificationModel - nn.Module class with an embedding bag and a linear layer for manipulating torchtext library</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class) -> None:\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "        return None\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        return None\n",
    "    \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "    \n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>predict - uses input model to predict input text, returns category number</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "def predict(text, text_pipeline, preModel) -> int:\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = preModel(text, torch.tensor([0]))\n",
    "    return output.argmax(1).item() + 1\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3ee2c",
   "metadata": {},
   "source": [
    "### Training Functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li>evaluate - evaluation loop, takes dataloader as input, returns accuracy.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a68dad4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Training Functions\n",
    "def evaluate(dataloader, evModel) -> float:\n",
    "    evModel.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = evModel(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1)==label).sum().item()\n",
    "            total_count += label.size(0)       \n",
    "    return total_acc/total_count\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code\n",
    "The `AG_NEWS` dataset has 4 labels, and therefore for classes:\n",
    "`1: World`, `2: Sports`, `3: Business` and `4:Sci/Tec`. This is defined in [Importing and preparing data sets](#Importing-and-preparing-data-sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea7a6a",
   "metadata": {},
   "source": [
    "#### Reloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0885f199",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 95811\n",
      "Emsize 64\n",
      "Num class: 4\n"
     ]
    }
   ],
   "source": [
    "#Reading in the meta file\n",
    "with open(f'{fileName}_meta.txt', 'r') as f:\n",
    "    fileContents = f.read()\n",
    "    f.close()\n",
    "\n",
    "fileContents = [lineRead.split(': ') for lineRead in fileContents.split('\\n')]\n",
    "fileContents.pop() #additional remove to deal with classification dict\n",
    "fileContents.pop() #removes empty end line\n",
    "\n",
    "for descript, value in fileContents: #   \n",
    "    match descript:\n",
    "        case 'vocab_size':\n",
    "            assert vocab_size == int(value)\n",
    "            print(f\"Vocab size: {vocab_size}\")\n",
    "        case 'emsize':\n",
    "            emsize = int(value)\n",
    "            print(f\"Emsize {emsize}\")\n",
    "        case 'num_class':\n",
    "            num_class = int(value)\n",
    "            print(f\"Num class: {num_class}\")\n",
    "        case 'ag_news_label':\n",
    "            #find way to impor news label\n",
    "            continue\n",
    "        case _:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18be1791",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded:  TextClassificationModel(\n",
      "  (embedding): EmbeddingBag(95811, 64, mode=mean)\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model creation\n",
    "modelRE = TextClassificationModel(vocab_size, emsize, num_class)\n",
    "modelRE.load_state_dict(torch.load(f\"{fileName}_weights.pth\"))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
    "#find way to import this from meta file\n",
    "\n",
    "print(\"Model reloaded: \", modelRE.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01161a",
   "metadata": {},
   "source": [
    "#### Evaluate the model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87bae056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "Test accuracy:    0.909\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test = evaluate(test_dataloader, modelRE)\n",
    "print(\"Test accuracy: {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e744b5",
   "metadata": {},
   "source": [
    "#### Test on a random news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e85b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news story (Expected: Sports).\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "print(\"This is a %s news story (Expected: Sports).\" %\n",
    "      ag_news_label[predict(ex_text_str, text_pipeline, modelRE)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
