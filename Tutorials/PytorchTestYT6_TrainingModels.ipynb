{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Test Youtube Training Models\n",
    "Notebook for following along with Pytorch model building, using [Pytorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html) website tutorial. This notebook will be similar to the previous Pytorch Test notebooks, as the [youtube content](https://www.youtube.com/watch?v=jF43_wj_DCQ) covers similiar works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [
     1,
     5
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances.\n",
      "Training set has 10000 instances.\n",
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "                                                 train=True,\n",
    "                                                 transform=transform,\n",
    "                                                 download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "                                                   train=False,\n",
    "                                                   transform=transform,\n",
    "                                                   download=True)\n",
    "print(f\"Training set has {len(training_set)} instances.\")\n",
    "print(f\"Training set has {len(validation_set)} instances.\")\n",
    "print(\"Data sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": [
     1,
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined.\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "print(\"Loaders defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1aa14d001d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>GarmentClassifier - convolutional layered nn for classifying images</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self. fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li><b>matplotlib_imshow</b> - shows an input image</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code\n",
    "#### Dataset and DataLoader\n",
    "These classes encapsulate the process of pulling your data from storage and exposing it to your training loop in batchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ceea5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f869555",
   "metadata": {},
   "source": [
    "##### Convert this cell to code to preview images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe9d44",
   "metadata": {},
   "source": [
    "#### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790457c7",
   "metadata": {},
   "source": [
    "#### Loss Function\n",
    "Below is a demonstration of implementing the loss function using cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143b57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9723, 0.5379, 0.5921, 0.4921, 0.8621, 0.2427, 0.6276, 0.1297, 0.6423,\n",
      "         0.8299],\n",
      "        [0.4719, 0.2032, 0.5063, 0.5815, 0.3624, 0.1268, 0.3638, 0.8573, 0.2414,\n",
      "         0.3413],\n",
      "        [0.9080, 0.4103, 0.1342, 0.3986, 0.5414, 0.4161, 0.5911, 0.1580, 0.9634,\n",
      "         0.0017],\n",
      "        [0.7062, 0.8295, 0.2613, 0.9366, 0.7074, 0.0130, 0.9735, 0.9418, 0.7061,\n",
      "         0.3764]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.3603768348693848\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print(f'Total loss for this batch: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08b2b4",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "Here stochastic gradient descent will be used. Experimenting with the parameters may lead to differences in the final model and the time it takes to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a832f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001,\n",
    "                            momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e442459",
   "metadata": {},
   "source": [
    "#### The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501a678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    \n",
    "    for i, data in enumerate(training_loader): \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/1000 #loss per batch\n",
    "            tb_x = epoch_index*len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "        \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bbeef",
   "metadata": {},
   "source": [
    "#### Per-Epoch Activity\n",
    "There are a couple of things that want to be done once per epoch: perform validation by checking relative loss on a non training data set; and to save a copy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c508cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "LOSS train: 0.43606860473344566 valid:0.458312451839447\n",
      "EPOCH 2\n",
      "LOSS train: 0.3329340219585865 valid:0.36159998178482056\n",
      "EPOCH 3\n",
      "LOSS train: 0.3172566526078663 valid:0.3329274654388428\n",
      "EPOCH 4\n",
      "LOSS train: 0.3038028375140166 valid:0.3305508494377136\n",
      "EPOCH 5\n",
      "LOSS train: 0.28264961366520586 valid:0.3201729357242584\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/fashion_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "best_vloss = 1_000_000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch_number + 1}\")\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    model.train(False)\n",
    "    running_vloss = 0.\n",
    "    for i, vdata in enumerate(validation_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "        \n",
    "    avg_vloss = running_vloss/(i+1)\n",
    "    print(f\"LOSS train: {avg_loss} valid:{avg_vloss}\")\n",
    "    \n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training' : avg_loss, 'Validation': avg_vloss},\n",
    "                      epoch_number + 1)\n",
    "    writer.flush()\n",
    "    \n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = \"model_{}_{}\".format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0680db5",
   "metadata": {},
   "source": [
    "To load a saved version of the model, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6970bca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13392/1099883373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGarmentClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    }
   ],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332868c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
