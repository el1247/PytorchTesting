{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Test Optimization\n",
    "Notebook for testing pytorch optimization, using [Pytorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) website tutorial.<br>\n",
    "[Main code](#Main-Code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib as mpl \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.ticker as ticker\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing data sets\n",
    "Importing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76441c10",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "print(\"Data imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91b3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8cadff",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303552d",
   "metadata": {},
   "source": [
    "### Classes\n",
    "<b>Class List:</b><br>\n",
    "<ul>\n",
    "<li>NeuralNetwork\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91026204",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "<li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "<li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa9fbf",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84466501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(\"Model created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95591807",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Hyperparameters\n",
    "These are adjustable parameters that let you control the model optimization process.\n",
    "<ul>\n",
    "<li> <b>Number of Epochs</b> - Number of times to iterate over the dataset\n",
    "<li> <b>Batch Size</b> - Number of data samples propagated through the network before the parameters are updated\n",
    "<li> <b>Learning Rate</b> - how much to update model parameters af each batch/epoch\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b6c9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885e631",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Optimzation Loop\n",
    "Once the hyperparameters are set, we can train and optimize the model within a loop. Each loop is called an epoch, which consists of:\n",
    "<ul>\n",
    "    <li> <b>The Train Loop</b> - iterate over the training data set to  try to converge to optimal parameters.\n",
    "    <li> <b>The Validation/Test Loop</b> - iterate over the test dataset to check if the model performance is improving.\n",
    "</ul>\n",
    "\n",
    "A loss function is used to measure the degree of dissimilarity between achieved results and target results. The aim is to minimise this value. Loss function calculation can be done many ways, such as nn.MSELoss (Mean Square Error) for regression, and nn.NLLLoss (Negative Log Likelihood) for classification. nn.CrossEntropyLoss combined nn.LogSoftmax and nn.NLLLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6610e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() #initialises the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60676169",
   "metadata": {},
   "source": [
    "#### Optimzer\n",
    "Different algorithms will influence how the optimization is performed. Here Stochastic Gradient Descent is used, however all optimization logic can be found in the optimizer object.<br>\n",
    "<ul>\n",
    "<li>Call optimizer.zero_grad() to reset gradients of model parameters. These naturally sum, so explicitly set to zero for each iteration.\n",
    "<li> Backpropagate the prediction loss with a call to loss.backward().\n",
    "<li> With the gradients aquired, call optimizer.step() to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cd22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d23acc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Function definitions, placed here for reference to text.\n",
    "#In future these will be in the calculation functions section\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X) #Prediction\n",
    "        loss = loss_fn(pred, y) #Loss calculation\n",
    "        \n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%. Avg loss: {test_loss:>8f} \\n\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "430fc5bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "Loss: 2.287969 [    0/60000]\n",
      "Loss: 2.284813 [ 6400/60000]\n",
      "Loss: 2.267748 [12800/60000]\n",
      "Loss: 2.270954 [19200/60000]\n",
      "Loss: 2.251211 [25600/60000]\n",
      "Loss: 2.206866 [32000/60000]\n",
      "Loss: 2.225328 [38400/60000]\n",
      "Loss: 2.179990 [44800/60000]\n",
      "Loss: 2.183382 [51200/60000]\n",
      "Loss: 2.147009 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.9%. Avg loss: 2.148619 \n",
      "\n",
      "Epoch 2\n",
      "---------------------------\n",
      "Loss: 2.154948 [    0/60000]\n",
      "Loss: 2.149064 [ 6400/60000]\n",
      "Loss: 2.093690 [12800/60000]\n",
      "Loss: 2.112406 [19200/60000]\n",
      "Loss: 2.065091 [25600/60000]\n",
      "Loss: 1.991369 [32000/60000]\n",
      "Loss: 2.021359 [38400/60000]\n",
      "Loss: 1.938169 [44800/60000]\n",
      "Loss: 1.943306 [51200/60000]\n",
      "Loss: 1.864984 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%. Avg loss: 1.871257 \n",
      "\n",
      "Epoch 3\n",
      "---------------------------\n",
      "Loss: 1.907255 [    0/60000]\n",
      "Loss: 1.875286 [ 6400/60000]\n",
      "Loss: 1.758144 [12800/60000]\n",
      "Loss: 1.796868 [19200/60000]\n",
      "Loss: 1.696050 [25600/60000]\n",
      "Loss: 1.646194 [32000/60000]\n",
      "Loss: 1.657471 [38400/60000]\n",
      "Loss: 1.561798 [44800/60000]\n",
      "Loss: 1.581964 [51200/60000]\n",
      "Loss: 1.475414 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%. Avg loss: 1.499993 \n",
      "\n",
      "Epoch 4\n",
      "---------------------------\n",
      "Loss: 1.572152 [    0/60000]\n",
      "Loss: 1.535913 [ 6400/60000]\n",
      "Loss: 1.381452 [12800/60000]\n",
      "Loss: 1.455442 [19200/60000]\n",
      "Loss: 1.345830 [25600/60000]\n",
      "Loss: 1.343942 [32000/60000]\n",
      "Loss: 1.350383 [38400/60000]\n",
      "Loss: 1.274496 [44800/60000]\n",
      "Loss: 1.302172 [51200/60000]\n",
      "Loss: 1.211598 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%. Avg loss: 1.238830 \n",
      "\n",
      "Epoch 5\n",
      "---------------------------\n",
      "Loss: 1.318042 [    0/60000]\n",
      "Loss: 1.302028 [ 6400/60000]\n",
      "Loss: 1.125487 [12800/60000]\n",
      "Loss: 1.239413 [19200/60000]\n",
      "Loss: 1.123390 [25600/60000]\n",
      "Loss: 1.148835 [32000/60000]\n",
      "Loss: 1.166712 [38400/60000]\n",
      "Loss: 1.098652 [44800/60000]\n",
      "Loss: 1.129046 [51200/60000]\n",
      "Loss: 1.057953 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%. Avg loss: 1.078959 \n",
      "\n",
      "Epoch 6\n",
      "---------------------------\n",
      "Loss: 1.149463 [    0/60000]\n",
      "Loss: 1.156845 [ 6400/60000]\n",
      "Loss: 0.958767 [12800/60000]\n",
      "Loss: 1.104867 [19200/60000]\n",
      "Loss: 0.989799 [25600/60000]\n",
      "Loss: 1.017877 [32000/60000]\n",
      "Loss: 1.053142 [38400/60000]\n",
      "Loss: 0.987347 [44800/60000]\n",
      "Loss: 1.017236 [51200/60000]\n",
      "Loss: 0.960613 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%. Avg loss: 0.975765 \n",
      "\n",
      "Epoch 7\n",
      "---------------------------\n",
      "Loss: 1.032196 [    0/60000]\n",
      "Loss: 1.062405 [ 6400/60000]\n",
      "Loss: 0.844841 [12800/60000]\n",
      "Loss: 1.014505 [19200/60000]\n",
      "Loss: 0.906152 [25600/60000]\n",
      "Loss: 0.925042 [32000/60000]\n",
      "Loss: 0.978032 [38400/60000]\n",
      "Loss: 0.914874 [44800/60000]\n",
      "Loss: 0.940592 [51200/60000]\n",
      "Loss: 0.894302 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%. Avg loss: 0.905002 \n",
      "\n",
      "Epoch 8\n",
      "---------------------------\n",
      "Loss: 0.946026 [    0/60000]\n",
      "Loss: 0.996254 [ 6400/60000]\n",
      "Loss: 0.763429 [12800/60000]\n",
      "Loss: 0.949776 [19200/60000]\n",
      "Loss: 0.850147 [25600/60000]\n",
      "Loss: 0.857021 [32000/60000]\n",
      "Loss: 0.924961 [38400/60000]\n",
      "Loss: 0.866414 [44800/60000]\n",
      "Loss: 0.885946 [51200/60000]\n",
      "Loss: 0.846291 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%. Avg loss: 0.853911 \n",
      "\n",
      "Epoch 9\n",
      "---------------------------\n",
      "Loss: 0.879861 [    0/60000]\n",
      "Loss: 0.946105 [ 6400/60000]\n",
      "Loss: 0.702967 [12800/60000]\n",
      "Loss: 0.901334 [19200/60000]\n",
      "Loss: 0.809995 [25600/60000]\n",
      "Loss: 0.805913 [32000/60000]\n",
      "Loss: 0.884566 [38400/60000]\n",
      "Loss: 0.832672 [44800/60000]\n",
      "Loss: 0.845362 [51200/60000]\n",
      "Loss: 0.809183 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%. Avg loss: 0.815058 \n",
      "\n",
      "Epoch 10\n",
      "---------------------------\n",
      "Loss: 0.827086 [    0/60000]\n",
      "Loss: 0.905776 [ 6400/60000]\n",
      "Loss: 0.656296 [12800/60000]\n",
      "Loss: 0.863755 [19200/60000]\n",
      "Loss: 0.779316 [25600/60000]\n",
      "Loss: 0.766843 [32000/60000]\n",
      "Loss: 0.851692 [38400/60000]\n",
      "Loss: 0.807648 [44800/60000]\n",
      "Loss: 0.813819 [51200/60000]\n",
      "Loss: 0.778832 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%. Avg loss: 0.784018 \n",
      "\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n---------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bc082",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2cd62",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
