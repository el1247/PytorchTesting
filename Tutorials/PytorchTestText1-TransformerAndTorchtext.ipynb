{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Language modeling\n",
    "Notebook for following along with Pytorch Text interpretation tutorial, starting with nn.transformer and torchtext [Pytorch](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) website tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import captum\n",
    "import copy\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from typing import Tuple\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = 'cpu' #Cuda having issues on PC, so manual setting to cpu\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Gather datasets and prepare them for consumption\n",
    "train_iter = WikiText2(split='train') #\"consumed to make vocab\"\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensors.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t:t.numel() > 0, data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "print(\"Data sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined, running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into bsz seperate sequences, removing extra elements that wouldn't\n",
    "        cleanly fit.   \n",
    "    Args: \n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "        \n",
    "    Returns:\n",
    "        Tensor of shap [N // bsz, bsz]\"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, eval_batch_size)\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)\n",
    "print(f\"Loaders defined, running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x262cf414030>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>TransformerModel - Language interpretting model.</li>\n",
    "    <li>PositionalEncoding - Injects information about the relative or absolute position of tokens in the sequence.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                nlayers: int, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "        self.init_weights()\n",
    "        return None\n",
    "    \n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"Args: \n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "        Returns:\n",
    "            output Tensor, shape [seq_len, btch_size, ntoken]\"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        print(src[0])\n",
    "        output = self.transformer_encoder(src, src_mask) #Returning Nans\n",
    "        print(output[0])\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position*div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Args: \n",
    "            x: Tensors, shape[seq_len, batch_size, embedding_dim]\"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "        \n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>get_batch - generates a pair of input-target sequences for the transformer model. It subdivides the source data into chunks of length bptt. For language modelling, the model needs the following words as Target.</li>\n",
    "    <li>generate_square_subsequent_mask - generates an upper triangular matrix of -inf with zeros on the diagonal.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "bptt = 35\n",
    "\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq)len, batch)size]\n",
    "            and target has shape [seq_len * batch_size]\"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "        \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "        return torch.triu(torch.ones(sz, sz) * float('inf'), diagonal=1)\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code\n",
    "#### Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e539b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)\n",
    "emsize = 200\n",
    "d_hid = 200\n",
    "nlayers = 2\n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid,\n",
    "    nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c2ad3",
   "metadata": {},
   "source": [
    "#### Running the model\n",
    "Here CrossEntropyLoss with a stochastic gradient descent optimizer will be used, with an initial learning rate of 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189999b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e9c317",
   "metadata": {
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module) -> None:\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    \n",
    "    num_batches = len(train_data)//bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt: #only on last batch\n",
    "            src = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch%log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time)*1000/log_interval\n",
    "            cur_loss = total_loss/log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | ' \n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | ' \n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    return None\n",
    "    \n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    print(output)\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23314dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6873,  1.4845,  0.0000,  ..., -0.0578, -0.0000, -0.4876],\n",
      "        [-0.4326,  2.4338, -0.4858,  ...,  2.2118, -0.6829,  1.8163],\n",
      "        [-0.1595, -0.3593, -0.3117,  ...,  0.3842,  0.4013,  0.9999],\n",
      "        ...,\n",
      "        [ 0.0000,  0.3532, -0.7597,  ...,  0.4141, -0.5299,  0.1242],\n",
      "        [-1.4031,  1.4968,  1.7497,  ...,  0.9308,  0.0000,  0.1420],\n",
      "        [-0.7210,  1.7287, -1.5678,  ...,  0.9894, -1.1219,  0.3163]])\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "35 tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "with torch.no_grad():\n",
    "    data, targets = get_batch(val_data, 0)\n",
    "    seq_len = data.size(0)\n",
    "    output = model(data, src_mask)\n",
    "\n",
    "print(len(output), output[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91d77eeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3498,  1.1876,  0.7018,  ..., -0.0462, -1.3900, -0.3901],\n",
      "        [-0.3461,  1.9470, -0.3886,  ...,  1.7694, -0.5463,  1.4530],\n",
      "        [-0.1276, -0.2874, -0.2494,  ...,  0.3073,  0.3211,  0.7999],\n",
      "        ...,\n",
      "        [ 0.6089,  0.2826, -0.6078,  ...,  0.3313, -0.4240,  0.0994],\n",
      "        [-1.1225,  1.1974,  1.3998,  ...,  0.7447,  1.0546,  0.1136],\n",
      "        [-0.5768,  1.3830, -1.2542,  ...,  0.7915, -0.8975,  0.2530]])\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_data[0:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79fe2c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7047,  0.5901,  0.6362,  ...,  0.0729, -1.0656,  1.9538],\n",
      "        [-0.1803,  0.6579,  0.3755,  ...,  1.9325,  1.3520, -0.1598],\n",
      "        [ 1.3546,  1.4502, -0.8175,  ...,  1.4399,  0.6179,  1.1222],\n",
      "        ...,\n",
      "        [-0.2986,  1.0477, -0.8262,  ...,  0.7058,  1.2391,  2.3242],\n",
      "        [-0.7235,  0.5183,  1.0280,  ...,  1.8370,  0.9076,  2.1543],\n",
      "        [ 0.7409, -0.2966, -0.7643,  ...,  2.0375, -1.3708,  0.3697]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.7047,  0.5901,  0.6362,  ...,  0.0729, -1.0656,  1.9538],\n",
      "        [-0.1803,  0.6579,  0.3755,  ...,  1.9325,  1.3520, -0.1598],\n",
      "        [ 1.3546,  1.4502, -0.8175,  ...,  1.4399,  0.6179,  1.1222],\n",
      "        ...,\n",
      "        [-0.2986,  1.0477, -0.8262,  ...,  0.7058,  1.2391,  2.3242],\n",
      "        [-0.7235,  0.5183,  1.0280,  ...,  1.8370,  0.9076,  2.1543],\n",
      "        [ 0.7409, -0.2966, -0.7643,  ...,  2.0375, -1.3708,  0.3697]])\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n",
      "tensor([[-0.7047,  0.5901,  0.6362,  ...,  0.0729, -1.0656,  1.9538],\n",
      "        [-0.1803,  0.6579,  0.3755,  ...,  1.9325,  1.3520, -0.1598],\n",
      "        [ 1.3546,  1.4502, -0.8175,  ...,  1.4399,  0.6179,  1.1222],\n",
      "        ...,\n",
      "        [-0.2986,  1.0477, -0.8262,  ...,  0.7058,  1.2391,  2.3242],\n",
      "        [-0.7235,  0.5183,  1.0280,  ...,  1.8370,  0.9076,  2.1543],\n",
      "        [ 0.7409, -0.2966, -0.7643,  ...,  2.0375, -1.3708,  0.3697]])\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/Text1')\n",
    "writer.add_graph(model, (val_data[0:35], src_mask)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baf94ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., inf, inf,  ..., inf, inf, inf],\n",
      "        [0., 0., inf,  ..., inf, inf, inf],\n",
      "        [0., 0., 0.,  ..., inf, inf, inf],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., inf, inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., inf],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "src = val_data[0:35]\n",
    "src = model.encoder(src) * math.sqrt(model.d_model)\n",
    "src = model.pos_encoder(src)\n",
    "output = model.transformer_encoder(src, src_mask) #Returning Nans\n",
    "print(src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b668995",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "register_buffer() missing 2 required positional arguments: 'name' and 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35344/21879421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: register_buffer() missing 2 required positional arguments: 'name' and 'tensor'"
     ]
    }
   ],
   "source": [
    "model.pos_encoder.register_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b9c55e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_35344/1628758292.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ellaw\\AppData\\Local\\Temp/ipykernel_35344/1628758292.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    x =\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x =\n",
    "#Forced notepad breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11766ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    val_ppl = math.exp(val_loss)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print('-'*90)\n",
    "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f} | '\n",
    "         f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "    print('-'*90)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
