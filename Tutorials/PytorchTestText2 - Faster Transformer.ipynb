{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Better Language modeling\n",
    "Notebook for following along with Pytorch Text interpretation tutorial, starting with nn.transformer and torchtext [Pytorch](https://pytorch.org/tutorials/beginner/bettertransformer_tutorial.html)  website tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import captum\n",
    "import copy\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from typing import Tuple\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from torchtext.models import RobertaClassificationHead\n",
    "from torchtext.functional import to_tensor\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = 'cpu' #Cuda having issues on PC, so manual setting to cpu\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Gather datasets and prepare them for consumption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "small_input_batch = [\"Hello world\", \"How are you!\"]\n",
    "big_input_batch = [\"Hello world\", \"How are you!\",\n",
    "                   \"\"\"`Well, Prince, so Genoa and Lucca are now just family estates of the\n",
    "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
    "if you still try to defend the infamies and horrors perpetrated by\n",
    "that Antichrist- I really believe he is Antichrist- I will have\n",
    "nothing more to do with you and you are no longer my friend, no longer\n",
    "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
    "I have frightened you- sit down and tell me all the news.`\n",
    "\n",
    "It was in July, 1805, and the speaker was the well-known Anna\n",
    "Pavlovna Scherer, maid of honor and favorite of the Empress Marya\n",
    "Fedorovna. With these words she greeted Prince Vasili Kuragin, a man\n",
    "of high rank and importance, who was the first to arrive at her\n",
    "reception. Anna Pavlovna had had a cough for some days. She was, as\n",
    "she said, suffering from la grippe; grippe being then a new word in\n",
    "St. Petersburg, used only by the elite.\"\"\"]\n",
    "\n",
    "print(\"Data sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined, running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "\n",
    "print(f\"Loaders defined, running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e11d220030>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>TransformerModel - Language interpretting model.</li>\n",
    "    <li>PositionalEncoding - Injects information about the relative or absolute position of tokens in the sequence.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>get_batch - generates a pair of input-target sequences for the transformer model. It subdivides the source data into chunks of length bptt. For language modelling, the model needs the following words as Target.</li>\n",
    "    <li>generate_square_subsequent_mask - generates an upper triangular matrix of -inf with zeros on the diagonal.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "\n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "\n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code\n",
    "#### Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c6f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_large = torchtext.models.XLMR_LARGE_ENCODER\n",
    "classifier_head = torchtext.models.RobertaClassificationHead(\n",
    "                    num_classes=2, input_dim = 1024)\n",
    "model = xlmr_large.get_model(head=classifier_head)\n",
    "transform = xlmr_large.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e968f",
   "metadata": {},
   "source": [
    "#### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342e55be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch = big_input_batch #Change between being and small\n",
    "ITERATIONS = 10\n",
    "\n",
    "model_input = to_tensor(transform(input_batch), padding_value=1)\n",
    "output = model(model_input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
