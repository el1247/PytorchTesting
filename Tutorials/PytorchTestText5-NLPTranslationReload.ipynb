{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Translation With A Sqeuence To Sequence Network and Attention\n",
    "Notebook for following along with Pytorch Text NLP From Scratch tutorials that is looking at creating a NN to translate French to English [Pytorch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)  website tutorial. <br><br>\n",
    "The data can be downloaded [here](https://download.pytorch.org/tutorial/data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu. Cuda available: False\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import unicodedata\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}. Cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Gather datasets and prepare them for consumption\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c)!= 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "print(\"Data sets functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "                read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs    \n",
    "\n",
    "def readLangsEval(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "                read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    print(f\"{len(pairs)} lines successfully read.\")\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "    return pairs    \n",
    "    \n",
    "print(\"\\nData sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined, running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "\n",
    "print(f\"Loaders defined, running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22095bb5f30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>Lang - Language encoder that converts words into a single hot-vector.</li>\n",
    "    <li>Encoder - Outputs some value for every word from the input sentence. For every input word the encord outputs a vector and a hidden state, which is used for the next input word.</li>\n",
    "    <li>Decoder - takes the encoder output vector(s) and outputs a sequence of words to create the translation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": [
     1,
     26,
     44,
     65
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class Lang:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2 #Count SOS and EOS\n",
    "        return None\n",
    "        \n",
    "    def addSentence(self, sentence) -> None:\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "        return None\n",
    "    \n",
    "    def addWord(self, word) -> None:\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        return None\n",
    "\n",
    "    \n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedding = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedding\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size) -> None:\n",
    "        super(DecoderRNN, self).init()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        ebeded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>filterPair - Checks if the data is below the length of MAX_LENGTH</li>\n",
    "    <li>filterPairs - returns elements in a list if below the MAX_LENGTH</li>\n",
    "    <li>prepareData - filters data by MAX_LENGTH, printing relevant information</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "def filterPair(p) -> bool:\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\\n\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\\n\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words, \"\\n\")\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareDataEval(lang1, lang2, reverse=False):\n",
    "    pairs = readLangsEval(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\\n\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\\n\" % len(pairs))\n",
    "    return pairs\n",
    "    \n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li>showPlot - plots input array, used for plot_losses</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "#plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points) -> None:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.title(\"Average Training Loss\")\n",
    "    plt.ylabel(\"Average Loss Value\")\n",
    "    plt.xlabel(\"Loss Check Point\")\n",
    "    return None\n",
    "    \n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6afb019",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d35444",
   "metadata": {},
   "source": [
    "#### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c67983c",
   "metadata": {
    "code_folding": [
     0,
     14,
     17
    ]
   },
   "outputs": [],
   "source": [
    "#Training Preparation Functions\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def asMinutes(s):\n",
    "    return '%dm %ds' % (s//60, s%60)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s/percent\n",
    "    rs = es - s\n",
    "    return '%s (est: %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971aa366",
   "metadata": {},
   "source": [
    "#### Evaluating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542145d0",
   "metadata": {
    "code_folding": [
     0,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                    encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        return decoded_words, decoder_attentions[:di+1]\n",
    "\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10) -> None:\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a4570",
   "metadata": {},
   "source": [
    "### Importing Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b48845",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = 'fra'\n",
    "lang2 = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a270b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4345 properly reloaded into input_lang: fra\n"
     ]
    }
   ],
   "source": [
    "input_lang = Lang(lang1)\n",
    "with open(f'{input_lang.name}_index2word.txt', 'r') as f:\n",
    "    input_lang_text = f.read()\n",
    "    f.close()\n",
    "    \n",
    "for pair in input_lang_text.split(', ')[2:]:\n",
    "    num, word = pair.split(': ')\n",
    "    input_lang.addWord(word.strip(\"''\"))\n",
    "\n",
    "for i in range(2, input_lang.n_words):\n",
    "    assert input_lang.word2index[input_lang.index2word[i]] == i, str(input_lang.index2word[i])+ \" doesnt equal \"+ str(i)+\" gives value \"+str(input_lang.word2index[input_lang.index2word[i]])\n",
    "    \n",
    "print(f\"{input_lang.n_words} properly reloaded into input_lang: {input_lang.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc66303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803 properly reloaded into input_lang: eng\n"
     ]
    }
   ],
   "source": [
    "output_lang = Lang(lang2)\n",
    "with open(f'{output_lang.name}_index2word.txt', 'r') as f:\n",
    "    output_lang_text = f.read()\n",
    "    f.close()\n",
    "    \n",
    "for pair in output_lang_text.split(', ')[2:]:\n",
    "    num, word = pair.split(': ')\n",
    "    output_lang.addWord(word.strip(\"''\"))\n",
    "\n",
    "for i in range(2, output_lang.n_words):\n",
    "    assert output_lang.word2index[output_lang.index2word[i]] == i, str(output_lang.index2word[i])+ \" doesnt equal \"+ str(i)+\" gives value \"+str(output_lang.word2index[output_lang.index2word[i]])\n",
    "    \n",
    "print(f\"{output_lang.n_words} properly reloaded into input_lang: {output_lang.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baae9bb",
   "metadata": {},
   "source": [
    "### Reloading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d017821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden_size: 256\n",
      "Input language name: fra\n",
      "Output language name: eng\n"
     ]
    }
   ],
   "source": [
    "with open(f'{input_lang.name}_{output_lang.name}_meta.txt', 'r') as f:\n",
    "    fileContents = f.read()\n",
    "    f.close()\n",
    "   \n",
    "fileContents = [lineRead.split(' ') for lineRead in fileContents.split('\\n')]\n",
    "fileContents.pop() #removes empty end line\n",
    "\n",
    "for descript, value in fileContents:\n",
    "    match descript:\n",
    "        case 'hidden_size:':\n",
    "            hidden_size = int(value)\n",
    "            print(f\"Hidden_size: {hidden_size}\")\n",
    "        case 'input_lang.n_words:':\n",
    "            assert input_lang.n_words == int(value)\n",
    "            print(f\"Input language name: {input_lang.name}\")\n",
    "        case 'output_lang.n_words:':\n",
    "            print(f\"Output language name: {output_lang.name}\")\n",
    "            assert output_lang.n_words == int(value)\n",
    "        case 'Attn_additional: dropout_p=':\n",
    "            dropout_pVal = int(value)\n",
    "            print(f\"droppit_pVal: {dropout_pVal}\")\n",
    "        case _:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b234a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(4345, 256)\n",
       "  (gru): GRU(256, 256)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderReload = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "encoderReload.load_state_dict(torch.load(f'encoder_{input_lang.name}_{output_lang.name}_weights.pth'))\n",
    "encoderReload.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f159d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding): Embedding(2803, 256)\n",
       "  (attn): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(256, 256)\n",
       "  (out): Linear(in_features=256, out_features=2803, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_decoderReload = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               dropout_p=0.1)\n",
    "attn_decoderReload.load_state_dict(torch.load(f'attn_decoder_{input_lang.name}_{output_lang.name}_weights.pth'))\n",
    "attn_decoderReload.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b599d5",
   "metadata": {},
   "source": [
    "### Reload Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0f5e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "135842 lines successfully read.\n",
      "Read 135842 sentence pairs\n",
      "\n",
      "Trimmed to 10599 sentence pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = prepareDataEval(lang2, lang1, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b178b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> elles sont toutes mortes .\n",
      "= they re all dead .\n",
      "< they re all dead . <EOS>\n",
      "\n",
      "> vous etes en retard .\n",
      "= you re very late .\n",
      "< you re very late . <EOS>\n",
      "\n",
      "> vous etes une de ces menteuses !\n",
      "= you are such a liar !\n",
      "< you are such a liar ! <EOS>\n",
      "\n",
      "> vous prechez un convaincu .\n",
      "= you re preaching to the choir .\n",
      "< you re preaching to the choir . <EOS>\n",
      "\n",
      "> c est une vraie commere .\n",
      "= she s a real gossip .\n",
      "< she s a real gossip . <EOS>\n",
      "\n",
      "> je suis flasque .\n",
      "= i m flabby .\n",
      "< i m finnish . <EOS>\n",
      "\n",
      "> vous n etes pas ainsi d ordinaire .\n",
      "= you re not usually like this .\n",
      "< you re not usually like this . <EOS>\n",
      "\n",
      "> vous n etes pas tres bon .\n",
      "= you re not very good .\n",
      "< you re not very good at <EOS>\n",
      "\n",
      "> elles sont dans la meme classe .\n",
      "= they are in the same class .\n",
      "< they are in the same class . <EOS>\n",
      "\n",
      "> je suis gaucher .\n",
      "= i m left handed .\n",
      "< i m being . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoderReload, attn_decoderReload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
