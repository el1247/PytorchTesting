{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Translation With A Sqeuence To Sequence Network and Attention\n",
    "Notebook for following along with Pytorch Text NLP From Scratch tutorials that is looking at creating a NN to translate French to English [Pytorch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)  website tutorial. <br><br>\n",
    "The data can be downloaded [here](https://download.pytorch.org/tutorial/data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu. Cuda available: False\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import unicodedata\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}. Cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Gather datasets and prepare them for consumption\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c)!= 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "print(\"Data sets functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "                read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs    \n",
    "    \n",
    "print(\"\\nData sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined, running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "\n",
    "print(f\"Loaders defined, running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ba4249df50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>Lang - Language encoder that converts words into a single hot-vector.</li>\n",
    "    <li>Encoder - Outputs some value for every word from the input sentence. For every input word the encord outputs a vector and a hidden state, which is used for the next input word.</li>\n",
    "    <li>Decoder - takes the encoder output vector(s) and outputs a sequence of words to create the translation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": [
     26,
     44,
     65
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class Lang:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2 #Count SOS and EOS\n",
    "        return None\n",
    "        \n",
    "    def addSentence(self, sentence) -> None:\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "        return None\n",
    "    \n",
    "    def addWord(self, word) -> None:\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        return None\n",
    "\n",
    "    \n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedding = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedding\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size) -> None:\n",
    "        super(DecoderRNN, self).init()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        ebeded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>filterPair - Checks if the data is below the length of MAX_LENGTH</li>\n",
    "    <li>filterPairs - returns elements in a list if below the MAX_LENGTH</li>\n",
    "    <li>prepareData - filters data by MAX_LENGTH, printing relevant information</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "def filterPair(p) -> bool:\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\\n\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\\n\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words, \"\\n\")\n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li>showPlot - plots input array, used for plot_losses</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "#plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points) -> None:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.title(\"Average Training Loss\")\n",
    "    plt.ylabel(\"Average Loss Value\")\n",
    "    plt.xlabel(\"Loss Check Point\")\n",
    "    return None\n",
    "    \n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6afb019",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0563e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "\n",
      "Trimmed to 10599 sentence pairs\n",
      "\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803 \n",
      "\n",
      "['il est tres fier de sa moto trafiquee .', 'he s very proud of his custom motorcycle .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d35444",
   "metadata": {},
   "source": [
    "#### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c67983c",
   "metadata": {
    "code_folding": [
     0,
     14,
     17
    ]
   },
   "outputs": [],
   "source": [
    "#Training Preparation Functions\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def asMinutes(s):\n",
    "    return '%dm %ds' % (s//60, s%60)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s/percent\n",
    "    rs = es - s\n",
    "    return '%s (est: %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971aa366",
   "metadata": {},
   "source": [
    "#### Evaluating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542145d0",
   "metadata": {
    "code_folding": [
     0,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                    encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        return decoded_words, decoder_attentions[:di+1]\n",
    "\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10) -> None:\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baae9bb",
   "metadata": {},
   "source": [
    "### Reloading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d017821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden_size: 256\n",
      "Input language name: fra\n",
      "Output language name: eng\n"
     ]
    }
   ],
   "source": [
    "with open(f'{input_lang.name}_{output_lang.name}_meta.txt', 'r') as f:\n",
    "    fileContents = f.read()\n",
    "    f.close()\n",
    "   \n",
    "fileContents = [lineRead.split(' ') for lineRead in fileContents.split('\\n')]\n",
    "fileContents.pop() #removes empty end line\n",
    "\n",
    "for descript, value in fileContents:\n",
    "    match descript:\n",
    "        case 'hidden_size:':\n",
    "            hidden_size = int(value)\n",
    "            print(f\"Hidden_size: {hidden_size}\")\n",
    "        case 'input_lang.n_words:':\n",
    "            assert input_lang.n_words == int(value)\n",
    "            print(f\"Input language name: {input_lang.name}\")\n",
    "        case 'output_lang.n_words:':\n",
    "            print(f\"Output language name: {output_lang.name}\")\n",
    "            assert output_lang.n_words == int(value)\n",
    "        case 'Attn_additional: dropout_p=':\n",
    "            dropout_pVal = int(value)\n",
    "            print(f\"droppit_pVal: {dropout_pVal}\")\n",
    "        case _:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b234a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(4345, 256)\n",
       "  (gru): GRU(256, 256)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderReload = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "encoderReload.load_state_dict(torch.load(f'encoder_{input_lang.name}_{output_lang.name}_weights.pth'))\n",
    "encoderReload.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f159d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding): Embedding(2803, 256)\n",
       "  (attn): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(256, 256)\n",
       "  (out): Linear(in_features=256, out_features=2803, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_decoderReload = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               dropout_p=0.1)\n",
    "attn_decoderReload.load_state_dict(torch.load(f'attn_decoder_{input_lang.name}_{output_lang.name}_weights.pth'))\n",
    "attn_decoderReload.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b599d5",
   "metadata": {},
   "source": [
    "### Reload Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b178b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> tu es intrepide .\n",
      "= you re fearless .\n",
      "< you re fearless . <EOS>\n",
      "\n",
      "> je suis tellement malade .\n",
      "= i am so sick .\n",
      "< i m so sick . <EOS>\n",
      "\n",
      "> il est tres honnete .\n",
      "= he is very honest .\n",
      "< he is very honest . <EOS>\n",
      "\n",
      "> il est tres courageux .\n",
      "= he is very brave .\n",
      "< he is very brave . <EOS>\n",
      "\n",
      "> j y suis habitue .\n",
      "= i m accustomed to this .\n",
      "< i m used to it . <EOS>\n",
      "\n",
      "> on va bien rigoler .\n",
      "= we re gonna have a lot of fun .\n",
      "< we re getting out . <EOS>\n",
      "\n",
      "> on n est jamais trop vieux pour apprendre .\n",
      "= you re never too old to learn .\n",
      "< you re never too old to learn . <EOS>\n",
      "\n",
      "> je suis retenue en otage .\n",
      "= i m being held hostage .\n",
      "< i m being held hostage . <EOS>\n",
      "\n",
      "> je suis en train de perdre mon temps .\n",
      "= i am wasting my time .\n",
      "< i m wasting my time . <EOS>\n",
      "\n",
      "> je ne sais pas bien nager .\n",
      "= i am poor at swimming .\n",
      "< i m in a afraid . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoderReload, attn_decoderReload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c3f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il agit en son nom propre .\n",
      "= he is acting on his own behalf .\n",
      "< he is acting on his own . <EOS>\n",
      "\n",
      "> il exerce sur elle du chantage .\n",
      "= she is being blackmailed by him .\n",
      "< he is at it all him . <EOS>\n",
      "\n",
      "> je ne suis pas sure d aimer ca .\n",
      "= i m not sure i like this .\n",
      "< i m not sure i like this . <EOS>\n",
      "\n",
      "> vous en etes en partie responsables .\n",
      "= you are in part responsible for it .\n",
      "< you are in part responsible for it . <EOS>\n",
      "\n",
      "> vous etes tres drole .\n",
      "= you re very funny .\n",
      "< you re very funny . <EOS>\n",
      "\n",
      "> je suis fatiguee de boston .\n",
      "= i m tired of boston .\n",
      "< i m tired of boston . <EOS>\n",
      "\n",
      "> je suis affame et assoiffe .\n",
      "= i m hungry and thirsty .\n",
      "< i m hungry and thirsty . <EOS>\n",
      "\n",
      "> je suis pret a mourir .\n",
      "= i am ready to die .\n",
      "< i am ready to die . <EOS>\n",
      "\n",
      "> je sur reagis .\n",
      "= i m overreacting .\n",
      "< i m kidding . <EOS>\n",
      "\n",
      "> elle est toujours soigneusement habillee .\n",
      "= she is always neatly dressed .\n",
      "< she is always neatly dressed . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoderReload, attn_decoderReload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang.index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
