{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df9348a",
   "metadata": {},
   "source": [
    "# Pytorch Text - Translation With A Sqeuence To Sequence Network and Attention\n",
    "Notebook for following along with Pytorch Text NLP From Scratch tutorials that is looking at creating a NN to translate French to English [Pytorch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)  website tutorial. <br><br>\n",
    "The data can be downloaded [here](https://download.pytorch.org/tutorial/data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec967837",
   "metadata": {},
   "source": [
    "### Choices for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e6fc7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699447fc",
   "metadata": {},
   "source": [
    "### Libaries and Modules\n",
    "Importing the necessary libaries and modules for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d660636a",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu. Cuda available: False\n",
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "#Import cell\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import unicodedata\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}. Cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d57c5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b8a2f",
   "metadata": {},
   "source": [
    "### Importing and preparing data sets\n",
    "Importing and preparing the data for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9d6461",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Gather datasets and prepare them for consumption\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c)!= 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "print(\"Data sets functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76441c10",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data sets successfully imported.\n"
     ]
    }
   ],
   "source": [
    "#Importing data sets\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "                read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs    \n",
    "    \n",
    "print(\"\\nData sets successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b051ffe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders defined, running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Loader definitions\n",
    "\n",
    "print(f\"Loaders defined, running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b04821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1784fced070>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting seed value\n",
    "torch.manual_seed(1247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f41a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e919b",
   "metadata": {},
   "source": [
    "### Class Definitions\n",
    "<b>Classes:</b><br>\n",
    "<ul>\n",
    "    <li>Lang - Language encoder that converts words into a single hot-vector.</li>\n",
    "    <li>Encoder - Outputs some value for every word from the input sentence. For every input word the encord outputs a vector and a hidden state, which is used for the next input word.</li>\n",
    "    <li>Decoder - takes the encoder output vector(s) and outputs a sequence of words to create the translation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f3a52d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes defined.\n"
     ]
    }
   ],
   "source": [
    "#Class definition cell\n",
    "class Lang:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2 #Count SOS and EOS\n",
    "        return None\n",
    "        \n",
    "    def addSentence(self, sentence) -> None:\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "        return None\n",
    "    \n",
    "    def addWord(self, word) -> None:\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        return None\n",
    "\n",
    "    \n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedding = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedding\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size) -> None:\n",
    "        super(DecoderRNN, self).init()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        return None\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        ebeded = self.dropout(embedded)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "print(\"Classes defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d966b5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae43c80",
   "metadata": {},
   "source": [
    "### Calculation functions\n",
    "<b>Functions:</b><br>\n",
    "<ul>\n",
    "    <li>filterPair - Checks if the data is below the length of MAX_LENGTH</li>\n",
    "    <li>filterPairs - returns elements in a list if below the MAX_LENGTH</li>\n",
    "    <li>prepareData - filters data by MAX_LENGTH, printing relevant information</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ba5a08",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Calculation functions cell\n",
    "def filterPair(p) -> bool:\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\\n\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\\n\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words, \"\\n\")\n",
    "    return input_lang, output_lang, pairs\n",
    "    \n",
    "print(\"Calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fee989",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0674ba3",
   "metadata": {},
   "source": [
    "### Plotting functions\n",
    "<b>Functions:</b>\n",
    "<ul>\n",
    "    <li>showPlot - plots input array, used for plot_losses</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b661aee3",
   "metadata": {
    "code_folding": [],
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting functions defined.\n"
     ]
    }
   ],
   "source": [
    "#Plotting functions Cell\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "def showPlot(points) -> None:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    return None\n",
    "    \n",
    "print(\"Plotting functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b08738",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e79a7",
   "metadata": {},
   "source": [
    "### Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6afb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0563e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "\n",
      "Trimmed to 10599 sentence pairs\n",
      "\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803 \n",
      "\n",
      "['je suis a la maison .', 'i am at home .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d35444",
   "metadata": {},
   "source": [
    "#### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c67983c",
   "metadata": {
    "code_folding": [
     14,
     17
    ]
   },
   "outputs": [],
   "source": [
    "#Training Preparation Functions\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1,1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def asMinutes(s):\n",
    "    return '%dm %ds' % (s//60, s%60)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s/percent\n",
    "    rs = es - s\n",
    "    return '%s (est: %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bd45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single training function\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "                                        input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device = device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random()<teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing: #Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_tensor[di]\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "    else: #Without teacher forcing: use own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach() #detatch from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item()==EOS_token: break\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item()/target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9c0d71",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Main training loop function\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, \n",
    "               plot_every=1000, learning_rate=0.01) -> None:\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) \n",
    "                         for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter%print_every==0:\n",
    "            print_loss_avg = print_loss_total/print_every\n",
    "            print_loss_total = 0\n",
    "            print('Duration %s (%d %d%%) %.4f' % \n",
    "                  (timeSince(start, iter/n_iters), iter, \n",
    "                   iter/n_iters *100, print_loss_avg))\n",
    "            \n",
    "        if iter%plot_every==0:\n",
    "            plot_losses.append(plot_loss_total/plot_every)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971aa366",
   "metadata": {},
   "source": [
    "#### Evaluating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "542145d0",
   "metadata": {
    "code_folding": [
     32
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                    encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        return decoded_words, decoder_attentions[:di+1]\n",
    "\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10) -> None:\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94dbb20",
   "metadata": {},
   "source": [
    "#### Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91548b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 4m 3s (est: 56m 48s) (5000 6%) 2.8331\n",
      "Duration 8m 6s (est: 52m 43s) (10000 13%) 2.2908\n",
      "Duration 12m 37s (est: 50m 31s) (15000 20%) 1.9721\n",
      "Duration 16m 49s (est: 46m 15s) (20000 26%) 1.7212\n",
      "Duration 21m 1s (est: 42m 3s) (25000 33%) 1.5151\n",
      "Duration 25m 26s (est: 38m 9s) (30000 40%) 1.3638\n",
      "Duration 29m 55s (est: 34m 12s) (35000 46%) 1.2115\n",
      "Duration 34m 16s (est: 29m 59s) (40000 53%) 1.0704\n",
      "Duration 38m 38s (est: 25m 45s) (45000 60%) 0.9473\n",
      "Duration 42m 57s (est: 21m 28s) (50000 66%) 0.8688\n",
      "Duration 47m 17s (est: 17m 11s) (55000 73%) 0.8076\n",
      "Duration 51m 38s (est: 12m 54s) (60000 80%) 0.7191\n",
      "Duration 55m 54s (est: 8m 36s) (65000 86%) 0.6449\n",
      "Duration 60m 17s (est: 4m 18s) (70000 93%) 0.6205\n",
      "Duration 64m 39s (est: 0m 0s) (75000 100%) 0.5489\n"
     ]
    }
   ],
   "source": [
    "teacher_forcing_ratio = 0.5 #Freq real target outputs are used as next input\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               dropout_p=0.1).to(device)\n",
    "#trainIters(encoder1, attn_decoder1, 100, print_every=20) #short training\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff54083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis responsable de sa protection .\n",
      "= i am responsible for her protection .\n",
      "< i am responsible for her her . <EOS>\n",
      "\n",
      "> elle est appreciee de tout le monde .\n",
      "= she is appreciated by everyone .\n",
      "< she is appreciated by everyone . <EOS>\n",
      "\n",
      "> elle est fiere de sa fille .\n",
      "= she is proud of her daughter .\n",
      "< she is proud of her daughter . <EOS>\n",
      "\n",
      "> je ne me sens pas seul .\n",
      "= i m not lonely .\n",
      "< i m not lonely . <EOS>\n",
      "\n",
      "> je suis seulement fatiguee .\n",
      "= i m just tired .\n",
      "< i m just tired . <EOS>\n",
      "\n",
      "> tu me mets mal a l aise .\n",
      "= you re embarrassing me .\n",
      "< you re embarrassing me . <EOS>\n",
      "\n",
      "> nous sommes en route .\n",
      "= we re on our way .\n",
      "< we re on way . <EOS>\n",
      "\n",
      "> nous sommes pour ainsi dire pretes .\n",
      "= we re about ready .\n",
      "< we re about ready . <EOS>\n",
      "\n",
      "> il est vieux .\n",
      "= he is old .\n",
      "< he is old . <EOS>\n",
      "\n",
      "> je suis en train de m entrainer .\n",
      "= i m exercising .\n",
      "< i m reading . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26b99a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
